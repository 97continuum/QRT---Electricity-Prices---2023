{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "35f35d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ca50534",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('X_train_NHkHMNU.csv')\n",
    "y_train = pd.read_csv('y_train_ZAN5mwg.csv')\n",
    "x_test = pd.read_csv('X_test_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab787c0",
   "metadata": {},
   "source": [
    "## Data cleaning (Yiru's code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f74c7194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                  0\n",
      "DAY_ID              0\n",
      "DE_CONSUMPTION      0\n",
      "FR_CONSUMPTION      0\n",
      "DE_FR_EXCHANGE      0\n",
      "FR_DE_EXCHANGE      0\n",
      "DE_NET_EXPORT       0\n",
      "FR_NET_EXPORT       0\n",
      "DE_NET_IMPORT       0\n",
      "FR_NET_IMPORT       0\n",
      "DE_GAS              0\n",
      "FR_GAS              0\n",
      "DE_COAL             0\n",
      "FR_COAL             0\n",
      "DE_HYDRO            0\n",
      "FR_HYDRO            0\n",
      "DE_NUCLEAR          0\n",
      "FR_NUCLEAR          0\n",
      "DE_SOLAR            0\n",
      "FR_SOLAR            0\n",
      "DE_WINDPOW          0\n",
      "FR_WINDPOW          0\n",
      "DE_LIGNITE          0\n",
      "DE_RESIDUAL_LOAD    0\n",
      "FR_RESIDUAL_LOAD    0\n",
      "DE_RAIN             0\n",
      "FR_RAIN             0\n",
      "DE_WIND             0\n",
      "FR_WIND             0\n",
      "DE_TEMP             0\n",
      "FR_TEMP             0\n",
      "GAS_RET             0\n",
      "COAL_RET            0\n",
      "CARBON_RET          0\n",
      "dtype: int64\n",
      "========================================\n",
      "0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1494 entries, 0 to 1493\n",
      "Data columns (total 35 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   ID                1494 non-null   int64  \n",
      " 1   DAY_ID            1494 non-null   int64  \n",
      " 2   COUNTRY           1494 non-null   object \n",
      " 3   DE_CONSUMPTION    1494 non-null   float64\n",
      " 4   FR_CONSUMPTION    1494 non-null   float64\n",
      " 5   DE_FR_EXCHANGE    1494 non-null   float64\n",
      " 6   FR_DE_EXCHANGE    1494 non-null   float64\n",
      " 7   DE_NET_EXPORT     1493 non-null   float64\n",
      " 8   FR_NET_EXPORT     1494 non-null   float64\n",
      " 9   DE_NET_IMPORT     1493 non-null   float64\n",
      " 10  FR_NET_IMPORT     1494 non-null   float64\n",
      " 11  DE_GAS            1494 non-null   float64\n",
      " 12  FR_GAS            1494 non-null   float64\n",
      " 13  DE_COAL           1494 non-null   float64\n",
      " 14  FR_COAL           1494 non-null   float64\n",
      " 15  DE_HYDRO          1494 non-null   float64\n",
      " 16  FR_HYDRO          1494 non-null   float64\n",
      " 17  DE_NUCLEAR        1494 non-null   float64\n",
      " 18  FR_NUCLEAR        1494 non-null   float64\n",
      " 19  DE_SOLAR          1494 non-null   float64\n",
      " 20  FR_SOLAR          1494 non-null   float64\n",
      " 21  DE_WINDPOW        1494 non-null   float64\n",
      " 22  FR_WINDPOW        1494 non-null   float64\n",
      " 23  DE_LIGNITE        1494 non-null   float64\n",
      " 24  DE_RESIDUAL_LOAD  1494 non-null   float64\n",
      " 25  FR_RESIDUAL_LOAD  1494 non-null   float64\n",
      " 26  DE_RAIN           1494 non-null   float64\n",
      " 27  FR_RAIN           1494 non-null   float64\n",
      " 28  DE_WIND           1494 non-null   float64\n",
      " 29  FR_WIND           1494 non-null   float64\n",
      " 30  DE_TEMP           1494 non-null   float64\n",
      " 31  FR_TEMP           1494 non-null   float64\n",
      " 32  GAS_RET           1494 non-null   float64\n",
      " 33  COAL_RET          1494 non-null   float64\n",
      " 34  CARBON_RET        1494 non-null   float64\n",
      "dtypes: float64(32), int64(2), object(1)\n",
      "memory usage: 408.6+ KB\n",
      "\n",
      "DataFrame Info:\n",
      " None\n",
      "DataFrame Shape: (1494, 35)\n"
     ]
    }
   ],
   "source": [
    "x_train.interpolate(method='polynomial',order=3, inplace=True)\n",
    "x_train_clean = x_train.drop(['COUNTRY'], axis=1).fillna(0)\n",
    "\n",
    "x_test.interpolate(method='polynomial',order=3, inplace=True)\n",
    "x_test_clean = x_test.drop(['COUNTRY'], axis=1).fillna(0)\n",
    "\n",
    "y_train_clean = y_train['TARGET']\n",
    "\n",
    "\n",
    "missing_values_x_train_clean = x_train_clean.isnull().sum()\n",
    "print(missing_values_x_train_clean)\n",
    "print(\"========================================\")\n",
    "\n",
    "missing_values_y_train_clean = y_train_clean.isnull().sum()\n",
    "print(missing_values_y_train_clean)\n",
    "\n",
    "\n",
    "print(\"\\nDataFrame Info:\\n\", x_train.info())\n",
    "\n",
    "shape = x_train.shape\n",
    "\n",
    "\n",
    "print(\"DataFrame Shape:\", shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb00c365",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee4f82e",
   "metadata": {},
   "source": [
    "### Run this for calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1bfd19be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and test sets\n",
    "x_train_final, x_test_final, y_train_final, y_test_final = train_test_split(x_train_clean, y_train_clean, test_size=0.2, random_state=42)\n",
    "\n",
    "#For model calibration\n",
    "X_train_array = x_train_final.values\n",
    "y_train_array = y_train_final.values\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_array, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_array, dtype=torch.float32)\n",
    "y_train_tensor = y_train_tensor.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e37685",
   "metadata": {},
   "source": [
    "### Run this for official testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6265c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dataframes to numpy arrays\n",
    "X_train_array = x_train_clean.values\n",
    "y_train_array = y_train_clean.values\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_array, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_array, dtype=torch.float32)\n",
    "y_train_tensor = y_train_tensor.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "38b93dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1195, 34)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a73bfd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the model\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ba189939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Fold 2/5\n",
      "Fold 3/5\n",
      "Fold 4/5\n",
      "Fold 5/5\n",
      "Average MSE: 1.2670537364482881\n"
     ]
    }
   ],
   "source": [
    "# Shuffle data before splitting (optional but recommended)\n",
    "#indices = np.random.permutation(len(x_train_clean))\n",
    "#X_train_shuffled = x_train_clean.iloc[indices]  # Use iloc to access rows by integer location\n",
    "#y_train_shuffled = x_train_clean.iloc[indices]\n",
    "\n",
    "# Define hyperparameters\n",
    "input_dim = x_train_clean.shape[1]\n",
    "hidden_dim = 64\n",
    "output_dim = 1  # Number of output neurons (for regression)\n",
    "learning_rate = 0.001\n",
    "num_epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "mse_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(x_train_clean)):\n",
    "    print(f\"Fold {fold + 1}/{k_folds}\")\n",
    "    \n",
    "    # Shuffle data before splitting\n",
    "    indices = np.random.permutation(len(x_train_clean))\n",
    "    x_train_shuffled = x_train_clean.iloc[indices]\n",
    "    y_train_shuffled = y_train_clean.iloc[indices]\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    X_train_fold, X_val_fold = x_train_shuffled.iloc[train_indices], x_train_shuffled.iloc[val_indices]\n",
    "    y_train_fold, y_val_fold = y_train_shuffled.iloc[train_indices], y_train_shuffled.iloc[val_indices]\n",
    "    \n",
    "    # Convert data to compatible data types\n",
    "    X_train_fold = X_train_fold.astype('float32')\n",
    "    y_train_fold = y_train_fold.astype('float32')\n",
    "    X_val_fold = X_val_fold.astype('float32')\n",
    "    y_val_fold = y_val_fold.astype('float32')\n",
    "    \n",
    "    # Convert data to PyTorch tensors\n",
    "    train_data = TensorDataset(torch.tensor(X_train_fold.values, dtype=torch.float32),\n",
    "                               torch.tensor(y_train_fold.values, dtype=torch.float32))\n",
    "    val_data = TensorDataset(torch.tensor(X_val_fold.values, dtype=torch.float32),\n",
    "                             torch.tensor(y_val_fold.values, dtype=torch.float32))\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "\n",
    "    # Initialize model\n",
    "    model = FeedForwardNN(input_dim, hidden_dim, output_dim)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.view(-1, 1))  # Reshape labels to match output dimension\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Evaluate model\n",
    "    model.eval()\n",
    "    mse = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            mse += criterion(outputs, labels.view(-1, 1)).item() / len(val_loader)\n",
    "    mse_scores.append(mse)\n",
    "    \n",
    "# Calculate average MSE across all folds\n",
    "average_mse = sum(mse_scores) / len(mse_scores)\n",
    "print(f\"Average MSE: {average_mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e6f62a",
   "metadata": {},
   "source": [
    "### TESTING USING THE ARTIFICIAL TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b89fc434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-Sample MSE: 1.270296509847992\n",
      "Out-of-Sample RMSE: 1.1270743142526103\n"
     ]
    }
   ],
   "source": [
    "# Convert the test set to PyTorch tensor\n",
    "X_test_tensor = torch.tensor(x_test_final.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_final.values, dtype=torch.float32)\n",
    "\n",
    "# Convert data to PyTorch tensor\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoader for the test set\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Evaluate model on test set\n",
    "model.eval()\n",
    "mse_test = 0.0\n",
    "num_samples = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        # Reshape the output tensor if needed\n",
    "        outputs = outputs.view(-1)  # Remove the extra dimension\n",
    "        # Reshape the labels tensor to match the shape of the outputs\n",
    "        labels = labels.view(-1)   # Ensure labels have the same shape as outputs\n",
    "        mse_test += criterion(outputs, labels).item() * len(inputs)\n",
    "        num_samples += len(inputs)\n",
    "mse_test /= num_samples\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "print(f\"Out-of-Sample MSE: {mse_test}\")\n",
    "print(f\"Out-of-Sample RMSE: {rmse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd14db67",
   "metadata": {},
   "source": [
    "### CREATING ESTIMATES FOR THE OFFICIAL TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ea4e4924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1115</td>\n",
       "      <td>0.503993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1202</td>\n",
       "      <td>0.866817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1194</td>\n",
       "      <td>0.466617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1084</td>\n",
       "      <td>0.436126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1135</td>\n",
       "      <td>0.281413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID    TARGET\n",
       "0  1115  0.503993\n",
       "1  1202  0.866817\n",
       "2  1194  0.466617\n",
       "3  1084  0.436126\n",
       "4  1135  0.281413"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the test set to PyTorch tensor\n",
    "X_test_tensor = torch.tensor(x_test_clean.values, dtype=torch.float32)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = model(X_test_tensor)\n",
    "\n",
    "# Convert the tensor predictions to a NumPy array\n",
    "y_pred = y_pred_tensor.numpy()\n",
    "\n",
    "# Load the \"ID\" column from the original test data\n",
    "id_column = x_test['ID']\n",
    "\n",
    "# Create a DataFrame to store the predictions along with the \"ID\" column\n",
    "predictions_df = pd.DataFrame({'ID': id_column, 'TARGET': y_pred.flatten()})\n",
    "\n",
    "# Save the predictions DataFrame to a CSV file\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "331113e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[131], line 20\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m feature_importance\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Assuming you have X_val and y_val as your validation data\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Assuming your model is already trained and stored in the variable `model`\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Convert validation data to PyTorch tensor\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m X_val_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_val\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     21\u001b[0m y_val_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_val\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Calculate feature importance\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_val' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to calculate feature importance\n",
    "def calculate_feature_importance(model, X_val, y_val):\n",
    "    feature_importance = {}\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        baseline_preds = model(X_val)\n",
    "        baseline_mse = mean_squared_error(y_val, baseline_preds)\n",
    "        for i, col in enumerate(X_val.columns):\n",
    "            X_val_shuffled = X_val.copy()\n",
    "            X_val_shuffled[col] = shuffle(X_val[col])\n",
    "            shuffled_preds = model(X_val_shuffled)\n",
    "            shuffled_mse = mean_squared_error(y_val, shuffled_preds)\n",
    "            feature_importance[col] = baseline_mse - shuffled_mse\n",
    "    return feature_importance\n",
    "\n",
    "# Assuming you have X_val and y_val as your validation data\n",
    "# Assuming your model is already trained and stored in the variable `model`\n",
    "\n",
    "# Convert validation data to PyTorch tensor\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "\n",
    "# Calculate feature importance\n",
    "feature_importance = calculate_feature_importance(model, X_val_tensor, y_val_tensor)\n",
    "\n",
    "# Rank features based on importance\n",
    "sorted_feature_importance = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "for feature, importance in sorted_feature_importance:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7114b50f",
   "metadata": {},
   "source": [
    "# CODE WITHOUT CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4709d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "input_dim = X_train_tensor.shape[1]  # Number of input features  # Number of input features\n",
    "hidden_dim = 64  # Number of neurons in the hidden layer\n",
    "output_dim = 1  # Number of output neurons (for regression)\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Create DataLoader for batching and shuffling the data\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate the model\n",
    "model = FeedForwardNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_train_tensor).numpy()\n",
    "\n",
    "# Make predictions (if needed)\n",
    "# y_pred = model(new_data_tensor).numpy()\n",
    "\n",
    "# Now you have y_pred containing the predicted values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc183031",
   "metadata": {},
   "source": [
    "## Running the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a5d0310",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(x_test_clean.values, dtype=torch.float32)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = model(X_test_tensor)\n",
    "\n",
    "# Convert the tensor predictions to a NumPy array\n",
    "y_pred = y_pred_tensor.numpy()\n",
    "\n",
    "# Load the \"ID\" column from the original test data\n",
    "id_column = x_test['ID']\n",
    "\n",
    "# Create a DataFrame to store the predictions along with the \"ID\" column\n",
    "predictions_df = pd.DataFrame({'ID': id_column, 'TARGET': y_pred.flatten()})\n",
    "\n",
    "# Save the predictions DataFrame to a CSV file\n",
    "predictions_df.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
